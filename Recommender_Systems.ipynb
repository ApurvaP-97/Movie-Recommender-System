{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Recommender Systems.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Recommendation with User Ratings (Explicit Feedback) \n",
        "In this part, we focus on the rating prediction recommendation task with explicit feedback. We will:\n",
        "\n",
        "* load and process the MovieLens 1M dataset, \n",
        "* build a baseline estimation model,\n",
        "* build a collaborative filtering model,\n",
        "* build a matrix factorization model,\n",
        "* and try to improve upon these models.\n",
        "\n",
        "First, we need to load and preprocess the experiment dataset. We use the MovieLens 1M data from https://grouplens.org/datasets/movielens/1m/ in this homework. The code has been provided in the next cell, and you need to run it. The resulting data variables are: train_mat is the numpy array variable for training data of size (#users, #items) with non-zero entries representing user-item ratings, and zero entries representing unknown user-item ratings; and test_mat is the numpy array variable for testing data of size (#users, #items)."
      ],
      "metadata": {
        "id": "-WYe8-gUukM9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# if you're using colab, this is a clunky way to load the ratings.dat file we need\n",
        "# navigate in your finder to ratings.dat when asked\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "Y2Lw1dJmaTFg",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "a87c6c6d-33dc-4e85-f26e-d57eebe37dd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-900b889b-2055-4077-9681-0f9d4ab5b57c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-900b889b-2055-4077-9681-0f9d4ab5b57c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving ratings (1).dat to ratings (1).dat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.sparse import coo_matrix\n",
        "\n",
        "#data_df = pd.read_csv(io.BytesIO(uploaded['ratings (1).dat']), sep='::', names=[\"UserID\", \"MovieID\", \"Rating\", \"Timestamp\"])\n",
        "\n",
        "# if you are running this notebook locally, you can replace above with something like this:\n",
        "data_df = pd.read_csv('./ratings.dat', sep='::', names=[\"UserID\", \"MovieID\", \"Rating\", \"Timestamp\"])\n",
        "\n",
        "# First, generate dictionaries for mapping old id to new id for users and movies\n",
        "unique_MovieID = data_df['MovieID'].unique()\n",
        "unique_UserID = data_df['UserID'].unique()\n",
        "j = 0\n",
        "user_old2new_id_dict = dict()\n",
        "for u in unique_UserID:\n",
        "    user_old2new_id_dict[u] = j\n",
        "    j += 1\n",
        "j = 0\n",
        "movie_old2new_id_dict = dict()\n",
        "for i in unique_MovieID:\n",
        "    movie_old2new_id_dict[i] = j\n",
        "    j += 1\n",
        "    \n",
        "# Then, use the generated dictionaries to reindex UserID and MovieID in the data_df\n",
        "user_list = data_df['UserID'].values\n",
        "movie_list = data_df['MovieID'].values\n",
        "for j in range(len(data_df)):\n",
        "    user_list[j] = user_old2new_id_dict[user_list[j]]\n",
        "    movie_list[j] = movie_old2new_id_dict[movie_list[j]]\n",
        "data_df['UserID'] = user_list\n",
        "data_df['movieID'] = movie_list\n",
        "\n",
        "# generate train_df with 70% samples and test_df with 30% samples, and there should have no overlap between them.\n",
        "train_index = np.random.random(len(data_df)) <= 0.7\n",
        "train_df = data_df[train_index]\n",
        "test_df = data_df[~train_index]\n",
        "\n",
        "# generate train_mat and test_mat\n",
        "num_user = len(data_df['UserID'].unique())\n",
        "num_movie = len(data_df['MovieID'].unique())\n",
        "\n",
        "train_mat = coo_matrix((train_df['Rating'].values, (train_df['UserID'].values, train_df['MovieID'].values)), shape=(num_user, num_movie)).astype(float).toarray()\n",
        "test_mat = coo_matrix((test_df['Rating'].values, (test_df['UserID'].values, test_df['MovieID'].values)), shape=(num_user, num_movie)).astype(float).toarray()"
      ],
      "metadata": {
        "id": "E1h-s3WsacVs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a8138c6-76ed-4239-ed0a-6855f3d73ba3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  return func(*args, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = [i for i in test_mat[0] if i!=0]\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvHIVgxxiaQR",
        "outputId": "8e24c8ea-8742-41f9-c359-39bd3fab77ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5.0, 3.0, 4.0, 5.0, 3.0, 3.0, 3.0, 4.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 4.0, 4.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_mat),len(train_mat[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44zgAshJjDt5",
        "outputId": "f03133ce-dfe9-4071-ab02-d4496e3f08d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6040, 3706)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_mat),len(test_mat[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FC9XKljlT4k",
        "outputId": "03f0fab8-527c-487e-e77f-f0f97d000ebe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6040, 3706)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_mat == test_mat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SwFU4Aclpvr",
        "outputId": "27f39138-d4b2-4512-b500-ff7a718ea56e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[False, False, False, ...,  True,  True,  True],\n",
              "       [False,  True,  True, ...,  True,  True,  True],\n",
              "       [ True,  True,  True, ...,  True,  True,  True],\n",
              "       ...,\n",
              "       [ True,  True,  True, ...,  True,  True,  True],\n",
              "       [ True, False, False, ...,  True,  True,  True],\n",
              "       [False,  True,  True, ...,  True,  True,  True]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the Baseline Estimation Model\n",
        "\n",
        "First, let's implement a simple personalized recommendation model -- the baseline estimate -- introduced in class: $b_{u,i}=\\mu+b_i+b_u$, where $\\mu$ is the overall mean rating for all items, $b_u$ = average rating of user $u-\\mu$, $b_i$ = average rating of item $i-\\mu$. Store your prediction as a numpy array variable 'prediction_mat' of size (#users, #movies) with each entry showing the predicted rating for the corresponding user-movie pair.\n",
        "\n",
        "* Hint: for users who do not have ratings in train_mat, set $b_u=0$ for them; and for movies which do not have ratings in train_mat, set $b_i=0$ for them"
      ],
      "metadata": {
        "id": "hI_D_HSXzbaK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the prediction_mat by the baseline estimation recommendation algorithm\n",
        "# Your Code Here...\n",
        "user_sum = train_mat.sum(axis=1)\n",
        "movie_sum = train_mat.sum(axis=0)"
      ],
      "metadata": {
        "id": "SHqawSeQzpR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matrix_sum = train_mat.sum()\n",
        "global_average = matrix_sum/len(train_mat.nonzero()[0])\n",
        "global_average"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lt2P-KWLpHxw",
        "outputId": "31e10474-f7fc-4037-896c-5a93b566dec9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.5811211716986286"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_mat = train_mat.copy()\n",
        "prediction_mat[prediction_mat==0] = np.nan\n",
        "user_average = np.nanmean(prediction_mat,axis=1)\n",
        "movie_average = np.nanmean(prediction_mat,axis=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfqjbKd-slNY",
        "outputId": "80253f31-9630-4439-af4c-c9fb55b08cb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: Mean of empty slice\n",
            "  after removing the cwd from sys.path.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('User average:{}\\nMovie average:{}'.format(user_average,movie_average))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTXWAJKiuaW-",
        "outputId": "1db1b248-0b44-416d-bc95-9f1fd31363d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User average:[4.17647059 3.65625    3.86486486 ... 3.76470588 3.80898876 3.54693878]\n",
            "Movie average:[4.39899413 3.50285714 4.14058957 ... 1.                nan        nan]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b_i = movie_average - global_average\n",
        "b_u = user_average - global_average\n",
        "print('b_i:{}\\nb_u:{}'.format(b_i,b_u))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhDJMQQgvpST",
        "outputId": "a601ab2f-2edc-4b10-ab22-83cd8e8c87d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b_i:[ 0.81787296 -0.07826403  0.5594684  ... -2.58112117         nan\n",
            "         nan]\n",
            "b_u:[ 0.59534942  0.07512883  0.28374369 ...  0.18358471  0.22786759\n",
            " -0.0341824 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Setting users without rating and items without rating to 0 as suggested in the hint\n",
        "b_i[np.isnan(b_i)]=0\n",
        "b_u[np.isnan(b_u)]=0"
      ],
      "metadata": {
        "id": "94l76aE1xpAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for user in range(prediction_mat.shape[0]):\n",
        "  for movie in range(prediction_mat.shape[1]):\n",
        "      prediction_mat[user][movie] = global_average + b_i[movie] + b_u[user]\n",
        "\n",
        "print(prediction_mat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ai0krCtxwXJU",
        "outputId": "e42487e9-27dc-496a-ca41-820cda40f7a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[5.04349033 4.10612182 4.76316276 ... 1.63405478 5.63405478 4.21621622]\n",
            " [4.47013126 3.53276275 4.18980369 ... 1.06069571 5.06069571 3.64285714]\n",
            " [4.57727412 3.6399056  4.29694655 ... 1.16783857 5.16783857 3.75      ]\n",
            " ...\n",
            " [4.95227412 4.0149056  4.67194655 ... 1.54283857 5.54283857 4.125     ]\n",
            " [4.69312778 3.75575926 4.4128002  ... 1.28369222 5.28369222 3.86585366]\n",
            " [4.39147645 3.45410794 4.11114888 ... 0.9820409  4.9820409  3.56420233]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, with this prediction_mat based on the baseline estimate, let's calculate the RMSE to evaluate the quality of the baseline estimate model. Please print out the RMSE of your prediction_mat using test_mat in the next cell.\n"
      ],
      "metadata": {
        "id": "IXRS-CC_zpuT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate and print out the RMSE for your prediction_df and the test_df\n",
        "# Your Code Here...\n",
        "import math\n",
        "\n",
        "non_zero = 0\n",
        "sum = 0\n",
        "for u in range(len(prediction_mat)):\n",
        "    for m in range(len(prediction_mat[0])):\n",
        "        if test_mat[u][m]!=0:\n",
        "            non_zero+=1\n",
        "            sum += math.pow((test_mat[u][m] - prediction_mat[u][m]),2)\n",
        "\n",
        "rmse_error = math.sqrt(sum/non_zero)"
      ],
      "metadata": {
        "id": "sqMsJrtTzr8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('RMSE of prediction_mat using test_mat: {}'.format(rmse_error))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHEpk9ca1bkn",
        "outputId": "28e20b0a-343c-42b4-f4d6-e18e401692f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE of prediction_mat using test_mat: 0.9344457404253174\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Collaborative Filtering with Jaccard Similarity\n",
        "\n",
        "In this part, you need to build a collaborative filtering recommendation model with **Jaccard similarity** to predict user-movie ratings. \n",
        "\n",
        "The prediction of the score for a user-item pair $(u,i)$ should use the formulation: $p_{u,i}=\\bar{r}_u+\\frac{\\sum_{u^\\prime\\in N}s(u,u^\\prime)(r_{u^\\prime,i}-\\bar{r}_{u^\\prime})}{\\sum_{u^\\prime\\in N}|s(u, u^\\prime)|}$ as introduced in class, where $s(u, u^\\prime)$ is the Jaccard similarity. We set the size of $N$ as 10.\n",
        "\n",
        "In the next cell, you need to write your code to implement this algorithm, and generate a numpy array variable named 'prediction_mat' of size (#user, #movie) with each entry showing the predicted rating for the corresponding user-movie pair.\n",
        "\n",
        "* Hint: when you find the nearest neighbor set $N$ of a user $u$, do not include user $u$ in $N$  \n"
      ],
      "metadata": {
        "id": "3V_S-DXXztyu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the prediction_mat by your user-user collaborative filtering recommendation algorithm\n",
        "# Your Code Here...\n",
        "\n",
        "#Pre-computation\n",
        "train_hashable = map(tuple, train_mat)\n",
        "y = set(train_hashable)\n",
        "print(y)"
      ],
      "metadata": {
        "id": "Sxf9YBSDz3Gm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f09895fe-5643-42ea-a323-0ddc2d5ef02d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please print out the RMSE of your prediction_mat using test_mat in the next cell."
      ],
      "metadata": {
        "id": "jrtLUo75z3kx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate and print out the RMSE for your prediction_df and the test_df\n",
        "# Your Code Here...\n",
        "import torch\n",
        "import math\n",
        "torch.cuda.is_available()\n",
        "cuda = torch.device('cuda')"
      ],
      "metadata": {
        "id": "cAn9BwQ8z50h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "torch.cuda.synchronize()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "def jaccard_similarity(a,b):\n",
        "  intersect = torch.mul(a,b).to(\"cuda\")\n",
        "  union = a.add(b).to(\"cuda\")\n",
        "  return (intersect!=0).sum(1)/(union!=0).sum(1)"
      ],
      "metadata": {
        "id": "q3_AWajy4kL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorising each row of the matrix : train_mat[i] and multiplying with complete_matrix of dimension mxn\n",
        "def get_jaccard_matrix_s():\n",
        "    jaccard_matrix=[]\n",
        "    complete_matrix = torch.Tensor(train_mat).to(\"cuda\")\n",
        "\n",
        "    for i in range(train_mat.shape[0]):\n",
        "        jaccard_matrix.append(jaccard_similarity(torch.Tensor(train_mat[i]).to(\"cuda\") ,complete_matrix))\n",
        "\n",
        "    jaccard_matrix = torch.stack(jaccard_matrix).to (\"cuda\")\n",
        "    return jaccard_matrix"
      ],
      "metadata": {
        "id": "yMTuZa2ErgUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jaccard_matrix = get_jaccard_matrix_s()\n",
        "print(jaccard_matrix)\n",
        "sorted, sorted_indices = torch.sort(jaccard_matrix)"
      ],
      "metadata": {
        "id": "_d5Z9eIr4uU5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c9ff357-8518-44d7-8290-eff2c1e93393"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.0000, 0.0236, 0.0441,  ..., 0.0000, 0.0885, 0.0333],\n",
            "        [0.0236, 1.0000, 0.0472,  ..., 0.0089, 0.0221, 0.0723],\n",
            "        [0.0441, 0.0472, 1.0000,  ..., 0.0385, 0.0413, 0.0330],\n",
            "        ...,\n",
            "        [0.0000, 0.0089, 0.0385,  ..., 1.0000, 0.0392, 0.0397],\n",
            "        [0.0885, 0.0221, 0.0413,  ..., 0.0392, 1.0000, 0.0705],\n",
            "        [0.0333, 0.0723, 0.0330,  ..., 0.0397, 0.0705, 1.0000]],\n",
            "       device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting the prediction_matrix based on the formula\n",
        "def runPrediction(top_jaccard_val,top_idx):\n",
        "    train_mat_tensor = torch.Tensor(train_mat).to('cuda')\n",
        "    train_mat_tensor_copy = train_mat_tensor.clone().detach()\n",
        "    train_mat_tensor_copy[train_mat_tensor_copy == 0] = torch.nan\n",
        "    prediction_matrix = train_mat.copy()\n",
        "    userMeans = torch.nanmean(train_mat_tensor_copy, axis=1)\n",
        "    b_user = userMeans\n",
        "    \n",
        "    prediction_matrix = torch.Tensor(train_mat.copy()).to(\"cuda\")\n",
        "    top_jaccard_val=top_jaccard_val.to(\"cpu\")\n",
        "    for i in range(train_mat.shape[0]):\n",
        "        idxs=top_idx[i].to(\"cpu\")\n",
        "        jacSimVal=torch.Tensor(top_jaccard_val[i]).to(\"cuda\")\n",
        "        sub_n=[]\n",
        "        jaccard_n=[]\n",
        "        pred=[]\n",
        "        for dim1,dim2 in enumerate(idxs):\n",
        "            r_u=torch.Tensor(train_mat[dim2,:]).to(\"cuda\")\n",
        "            ru_i=r_u.clone().detach()\n",
        "            ru_i[ru_i>0]=1\n",
        "            subt=r_u-b_user[dim2]\n",
        "            subt=torch.mul(subt,ru_i).to(\"cuda\")\n",
        "            subt_nz=torch.mul(subt,jacSimVal[dim1]).to(\"cuda\")\n",
        "            sub_n.append(subt_nz)\n",
        "            jaccard_n.append(jacSimVal[dim1]*ru_i)\n",
        "\n",
        "    \n",
        "        sub_n=torch.stack(sub_n).to (\"cuda\")\n",
        "        jaccard_n=torch.stack(jaccard_n).to(\"cuda\")\n",
        "        sub_n=torch.sum(sub_n,0).to(\"cuda\")\n",
        "        jaccard_n=torch.sum(jaccard_n,0).to(\"cuda\")\n",
        "\n",
        "        prediction_matrix[i]=torch.divide(sub_n,jaccard_n).to(\"cuda\")\n",
        "    return prediction_matrix"
      ],
      "metadata": {
        "id": "sb9NiImf4zn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getRmse(prediction_matrix,neighbors):\n",
        "    prediction_matrix[torch.isnan(prediction_matrix)] = 0\n",
        "    prediction_matrix[prediction_matrix == float('inf')] = 0\n",
        "    prediction_matrix[prediction_matrix == -float('inf')] = 0\n",
        "    print()\n",
        "    print('Prediction Matrix')\n",
        "    print()\n",
        "    print (prediction_matrix)\n",
        "    print (prediction_matrix.shape)\n",
        "    print()\n",
        "\n",
        "\n",
        "    for i in range(train_mat.shape[0]):\n",
        "        prediction_matrix[i]=b_user[i]+prediction_matrix[i]\n",
        "    \n",
        "\n",
        "    err = 0\n",
        "    count = 0\n",
        "\n",
        "    for i in range(test_mat.shape[0]):\n",
        "        for j in range(test_mat.shape[1]):\n",
        "            if test_mat[i][j] > 0:\n",
        "                count=count+1\n",
        "                err= err+ math.pow(test_mat[i][j] - prediction_matrix[i][j], 2)\n",
        "\n",
        "    print('Calculated RMSE is for {} nearest neighbors is: {}'.format(neighbors,math.sqrt(err/count)))\n",
        "    print()"
      ],
      "metadata": {
        "id": "RYlLKmkOxBBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getPredictionForNeighbors(neighbors):\n",
        "    \n",
        "    idx_required = torch.LongTensor([i for i in range(-(neighbors+1),-1,1)])\n",
        "    top_jaccard_val=sorted[:,idx_required]\n",
        "    top_idx = sorted_indices[:, idx_required]\n",
        "    print('-----------------------Number of neighbors:{}-------------------------'.format(neighbors))\n",
        "    prediction_mat = runPrediction(top_jaccard_val,top_idx)\n",
        "    getRmse(prediction_mat,neighbors)\n"
      ],
      "metadata": {
        "id": "RLbkphpq4xQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neighbors = [10,30,50,100]\n",
        "for n in neighbors:\n",
        "    getPredictionForNeighbors(n)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jh-XQgTsuV53",
        "outputId": "efe6cf4c-fa62-45aa-c1aa-67bd358cc37c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------Number of neighbors:10-------------------------\n",
            "\n",
            "Prediction Matrix\n",
            "\n",
            "tensor([[ 1.0000, -1.1949,  1.1627,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 1.1000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.9300,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        ...,\n",
            "        [ 1.5882,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.1379, -0.0822,  0.6320,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.8764,  0.3087, -0.3091,  ...,  0.0000,  0.0000,  0.0000]],\n",
            "       device='cuda:0')\n",
            "torch.Size([6040, 3706])\n",
            "\n",
            "Calculated RMSE is for 10 nearest neighbors is: 1.0461161821434874\n",
            "\n",
            "-----------------------Number of neighbors:30-------------------------\n",
            "\n",
            "Prediction Matrix\n",
            "\n",
            "tensor([[ 0.2948, -0.8474,  0.5717,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.5339,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.6528,  0.0000,  1.6875,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        ...,\n",
            "        [ 0.6906,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0095, -0.8432,  0.6075,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.6731, -0.8297,  0.2871,  ...,  0.0000,  0.0000,  0.0000]],\n",
            "       device='cuda:0')\n",
            "torch.Size([6040, 3706])\n",
            "\n",
            "Calculated RMSE is for 30 nearest neighbors is: 0.9799902788441746\n",
            "\n",
            "-----------------------Number of neighbors:50-------------------------\n",
            "\n",
            "Prediction Matrix\n",
            "\n",
            "tensor([[ 0.4026, -0.5343,  0.4669,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.4862, -0.2785,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.3971, -0.1786,  1.6875,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        ...,\n",
            "        [ 0.5687,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.2490, -0.6090,  0.5768,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.7297, -0.8574,  0.3336,  ...,  0.0000,  0.0000,  0.0000]],\n",
            "       device='cuda:0')\n",
            "torch.Size([6040, 3706])\n",
            "\n",
            "Calculated RMSE is for 50 nearest neighbors is: 0.9565100486489685\n",
            "\n",
            "-----------------------Number of neighbors:100-------------------------\n",
            "\n",
            "Prediction Matrix\n",
            "\n",
            "tensor([[ 0.3770, -0.4765,  0.4844,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.4969, -0.6020,  0.1422,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.4207, -0.3148,  1.6875,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        ...,\n",
            "        [ 0.3313, -0.6143,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.3456, -0.5325,  0.5750,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.7021, -0.6508,  0.3349,  ...,  0.0000,  0.0000,  0.0000]],\n",
            "       device='cuda:0')\n",
            "torch.Size([6040, 3706])\n",
            "\n",
            "Calculated RMSE is for 100 nearest neighbors is: 0.9341995947715285\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparing the RMSE results of this collaborative filtering and the baseline estimate algorithm, what do you observe? Is the  collaborative filtering the one producing the best performance? What reasons do you think can explain what you observe?"
      ],
      "metadata": {
        "id": "kANk-3sez7bo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Answer:**\n",
        "1. RMSE of baseline estimate : 0.934\n",
        "2. RMSE of collaborative filtering : 0.934 with 100 neighbors, 1.04 with 10 neighbors.\n",
        "\n",
        "In collaborative filtering, for each  user, we pick the most similar N users to them. Based on the preferences of these simialr users, we predict how much rating this user might give for a particular movie. \n",
        "\n",
        "**Observations:**\n",
        "1. RMSE of collaborative filtering is higher when N=10. However, as we increase the number of neighbors to 100, the RMSE is much better when compared to baseline estimate. \n",
        "2. We have around 6k users, by increasing the number of nearest neighbors being considered, the prediction becomes more accurate. However, increasing N to more than 1000 may not ensure lower RMSE value. This is because, including too many users as neighbors to predict the ratings may result in too much generalization. \n",
        "3. Similarly, N=10 CF  performs worse(RMSE = 1.04) than baseline estimation since it considers very few neighbors. \n"
      ],
      "metadata": {
        "id": "HbqwznxdsOQM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Matrix Factorization\n",
        "\n",
        "Now we turn to matrix factorization. First, let's implement the matrix factorization (MF for short) model introduced in class. The MF model can be mathematically represented as: \n",
        "\n",
        "<center>$\\underset{\\mathbf{P},\\mathbf{Q}}{\\text{min}}\\,\\,L=\\sum_{(u,i)\\in\\mathcal{O}}(\\mathbf{P}_u\\cdot\\mathbf{Q}^\\top_i-r_{u,i})^2+\\lambda(\\lVert\\mathbf{P}\\rVert^2_{\\text{F}}+\\lVert\\mathbf{Q}\\rVert^2_{\\text{F}})$,</center>\n",
        "    \n",
        "where $\\mathbf{P}$ is the user latent factor matrix of size (#user, #latent); $\\mathbf{Q}$ is the movie latent factor matrix of size (#movie, #latent); $\\mathcal{O}$ is a user-movie pair set containing all user-movie pairs having ratings in train_mat; $r_{u,i}$ represents the rating for user u and movie i; $\\lambda(\\lVert\\mathbf{P}\\rVert^2_{\\text{F}}+\\lVert\\mathbf{Q}\\rVert^2_{\\text{F}})$ is the regularization term to overcome overfitting problem, $\\lambda$ is the regularization weight (a hyper-parameter manually set by developer, i.e., you), and $\\lVert\\mathbf{P}\\rVert^2_{\\text{F}}=\\sum_{x}\\sum_{y}(\\mathbf{P}_{x,y})^2$, $\\lVert\\mathbf{Q}\\rVert^2_{\\text{F}}=\\sum_{x}\\sum_{y}(\\mathbf{Q}_{x,y})^2$. Such an L function is called the **loss function** for the matrix factorization model. The goal of training an MF model is to find appropriate $\\mathbf{P}$ and $\\mathbf{Q}$ to minimize the loss L.\n",
        "\n",
        "To implement such an MF, here we will write a Python class for the model. There are three functions in this MF class: init, train, and predict. \n",
        "\n",
        "* The 'init' function (**already provided**) is to initialize the variables the MF class needs, which takes 5 inputs: train_mat, test_mat, latent, lr, and reg. 'train_mat' and 'test_mat' are the corresponfing training and testing matrices we have. 'latent' represents the latent dimension we set for the MF model. 'lr' represents the learning rate, i.e., the update step in each optimization iteration, default is 0.01. 'reg' represents the regularization weight, i.e., the $\\lambda$ in the MF formulation.\n",
        "\n",
        "* The 'train' function (**partially provided and need to complete**) is to train the MF model given the training data train_mat. There is only one input to this function: an int variable 'epoch' to indicate how many epochs for training the model. The main body of this function should be a loop for 'epoch' iterations. In each iteration, following the algorithm to update the MF model:\n",
        "\n",
        "        1. Randomly shuffle training user-movie pairs  (i.e., user-movie pairs having ratings in train_mat)\n",
        "        2. Have an inner loop to iterate each user-movie pair:\n",
        "                a. given a user-movie pair (u,i), update the user latent factor and movie latent factor by gradient decsent:    \n",
        "<center>$\\mathbf{P}_u=\\mathbf{P}_u-\\gamma [2(\\mathbf{P}_u\\cdot\\mathbf{Q}_i^\\top-r_{u,i})\\cdot\\mathbf{Q}_i+2\\lambda\\mathbf{P}_u]$</center>    \n",
        "<center>$\\mathbf{Q}_i=\\mathbf{Q}_i-\\gamma [2(\\mathbf{P}_u\\cdot\\mathbf{Q}_i^\\top-r_{u,i})\\cdot\\mathbf{P}_u+2\\lambda\\mathbf{Q}_i]$</center>    \n",
        "<center>where $\\mathbf{P}_u$ and $\\mathbf{Q}_i$ are row vectors of size (1, #latent), $\\gamma$ is learning rate (default is 0.01), $\\lambda$ is regularization weight.</center>\n",
        "        \n",
        "        3. After iterating over all user-movie pairs, we have finished the training for the current epoch. Now calculate and print out the value of the loss function L after this epoch, and the RMSE on test_mat by the current MF model. Then append them to lists to keep a record of them.\n",
        "The train function needs to return two lists: 'epoch_loss_list' recording the loss after each training epoch, and 'epoch_test_RMSE_list' recording the RMSE on test_mat after each training epoch.\n",
        "\n",
        "* The 'predict' function (**already provided**) is to calculate the prediction_mat by the learned $\\mathbf{P}$ and $\\mathbf{Q}$.\n",
        "\n",
        "In the next cell, we provide the 'init' and 'predict' functions. You will need to fill in the 'train' function based on the description above. \n",
        "\n",
        "**NOTE that you should not delete or modify the provided code.**"
      ],
      "metadata": {
        "id": "6GCbSqrZ1PwQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MF:\n",
        "    def __init__(self, train_mat, test_mat, latent=5, lr=0.01, reg=0.01):\n",
        "        self.train_mat = train_mat  # the training rating matrix of size (#user, #movie)\n",
        "        self.test_mat = test_mat  # the training rating matrix of size (#user, #movie)\n",
        "        \n",
        "        self.latent = latent  # the latent dimension\n",
        "        self.lr = lr  # learning rate\n",
        "        self.reg = reg  # regularization weight, i.e., the lambda in the objective function\n",
        "        \n",
        "        self.num_user, self.num_movie = train_mat.shape\n",
        "        \n",
        "        self.sample_user, self.sample_movie = self.train_mat.nonzero()  # get the user-movie paris having ratings in train_mat\n",
        "        self.num_sample = len(self.sample_user)  # the number of user-movie pairs having ratings in train_mat\n",
        "\n",
        "        self.train_indicator_mat = 1.0 * (train_mat > 0)  # binary matrix to indicate whether s user-movie pair has rating or not in train_mat\n",
        "        self.test_indicator_mat = 1.0 * (test_mat > 0)  # binary matrix to indicate whether s user-movie pair has rating or not in test_mat\n",
        "\n",
        "        self.P = np.random.random((self.num_user, self.latent))  # latent factors for users, size (#user, self.latent), randomly initialized\n",
        "        self.Q = np.random.random((self.num_movie, self.latent))  # latent factors for users, size (#movie, self.latent), randomly initialized\n",
        "\n",
        "    def train(self, epoch=20, verbose=True):\n",
        "        \"\"\"\n",
        "        Goal: Write your code to train your matrix factorization model for epoch iterations in this function\n",
        "        Input: epoch -- the number of training epoch \n",
        "        Output: epoch_loss_list -- a list recording the training loss for each epoch\n",
        "                epoch_test_RMSE_list -- a list recording the testing RMSE after each training epoch\n",
        "        \"\"\"\n",
        "        epoch_loss_list = []\n",
        "        epoch_test_RMSE_list = []\n",
        "        for ep in range(epoch):\n",
        "            \"\"\" \n",
        "            Write your code here to implement the training process for one epoch, \n",
        "            and at the end of each epoch, print out the epoch number, the training loss after this epoch, \n",
        "            and the test RMSE after this epoch\n",
        "            \"\"\"\n",
        "\n",
        "            #Picking random user and item using shuffle function\n",
        "            training_indices = np.arange(self.num_sample)\n",
        "            np.random.shuffle(training_indices)\n",
        "            for index in training_indices:  \n",
        "                u=self.sample_user[index]\n",
        "                i=self.sample_movie[index]\n",
        "                \n",
        "                # Updating the P and Q latent factor matrices using gradient descent. Formula from the equation mentioned in the question\n",
        "                error_ui = train_mat[u,i] - self.P[u,:].dot(self.Q[i,:])\n",
        "                for j in range(self.latent):\n",
        "                    update = self.P[u][j].copy() + self.lr * (2 * error_ui * self.Q[i][j] - 2*self.reg * self.P[u][j])\n",
        "                    self.Q[i][j] += self.lr * (2 * error_ui * self.P[u][j] - 2*self.reg * self.Q[i][j])\n",
        "                    self.P[u][j] = update\n",
        "\n",
        "            # Computing training loss after each epoch.\n",
        "            E = (train_mat - self.P.dot(self.Q.T))**2\n",
        "            loss = E[train_mat.nonzero()].sum() + self.reg*((self.P**2).sum() +(self.Q**2).sum())\n",
        "            pred_matrix=self.predict()\n",
        "\n",
        "            # Computing test RMSE after each epoch\n",
        "            rmse_score=self.calculate_rmse(test_mat,pred_matrix)\n",
        "\n",
        "           \n",
        "            print('Epoch:{}  Loss:{}  RMSE_score:{}'.format(ep+1,loss,rmse_score))\n",
        "            epoch_loss_list.append(loss)\n",
        "            epoch_test_RMSE_list.append(rmse_score)\n",
        "\n",
        "            \"\"\"\n",
        "            End of your code for this function\n",
        "            \"\"\"\n",
        "        return epoch_loss_list, epoch_test_RMSE_list\n",
        "        \n",
        "\n",
        "    def calculate_rmse(self,actual,pred):\n",
        "        count=0\n",
        "        sum=0\n",
        "        for i in range(self.num_user):\n",
        "          for j in range(self.num_movie):\n",
        "            if actual[i][j]!=0:\n",
        "              sum+=(actual[i][j]-pred[i][j])**2\n",
        "              count+=1\n",
        "        return pow(sum/count,0.5)\n",
        "\n",
        "\n",
        "    def predict(self):\n",
        "        prediction_mat = np.matmul(self.P, self.Q.T)\n",
        "        return prediction_mat"
      ],
      "metadata": {
        "id": "ISJd_HvQ15ji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's train an MF model based on your implementation. The code is provided, you just need to excute the next cell. The expectations are: \n",
        "\n",
        "* first, the code can be successfully excuted without error; \n",
        "* and second, the training loss and RMSE on **test_mat** of each training epoch should be printed out for all 20 epochs.\n"
      ],
      "metadata": {
        "id": "rIpA5p5v19Oo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mf = MF(train_mat, test_mat, latent=5, lr=0.01, reg=0.001)\n",
        "epoch_loss_list, epoch_test_RMSE_list = mf.train(epoch=20)"
      ],
      "metadata": {
        "id": "8xBeR6gH2Avp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43371fe9-eef6-4c98-810c-5909bac1273d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1  Loss:610865.7308371149  RMSE_score:0.9515669804252719\n",
            "Epoch:2  Loss:597781.3863400008  RMSE_score:0.945730356571922\n",
            "Epoch:3  Loss:586311.4749284006  RMSE_score:0.9410168630513732\n",
            "Epoch:4  Loss:566651.8929471895  RMSE_score:0.9312108354967252\n",
            "Epoch:5  Loss:551184.2714029644  RMSE_score:0.923508778671051\n",
            "Epoch:6  Loss:538083.8138885034  RMSE_score:0.9165114945769472\n",
            "Epoch:7  Loss:528263.305247537  RMSE_score:0.9119019908006063\n",
            "Epoch:8  Loss:518894.6717339124  RMSE_score:0.9066756600530428\n",
            "Epoch:9  Loss:513709.2376504036  RMSE_score:0.9043481764557498\n",
            "Epoch:10  Loss:508178.56970574206  RMSE_score:0.9022163638451258\n",
            "Epoch:11  Loss:505112.0421342366  RMSE_score:0.9009106267038767\n",
            "Epoch:12  Loss:500074.0463960121  RMSE_score:0.8973389827368815\n",
            "Epoch:13  Loss:500118.0778517156  RMSE_score:0.8992484857294937\n",
            "Epoch:14  Loss:500116.37269078067  RMSE_score:0.8993579460518053\n",
            "Epoch:15  Loss:498174.25312779826  RMSE_score:0.8993615231211485\n",
            "Epoch:16  Loss:494796.4372613662  RMSE_score:0.8970219878813204\n",
            "Epoch:17  Loss:494167.8921775121  RMSE_score:0.897293290445552\n",
            "Epoch:18  Loss:494525.57705052505  RMSE_score:0.89820090528252\n",
            "Epoch:19  Loss:493352.19309150055  RMSE_score:0.8982970855328553\n",
            "Epoch:20  Loss:492015.26273127826  RMSE_score:0.8971654558221593\n"
          ]
        }
      ]
    }
  ]
}